{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformers: Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForObjectDetection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "url = 'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/segmentation_input.jpg'\n",
    "\n",
    "image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show image\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.imshow(np.asarray(image))\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model name\n",
    "model_name = 'facebook/detr-resnet-50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image processor\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# load model\n",
    "model = AutoModelForObjectDetection.from_pretrained(model_name, device_map='auto')\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipeline (preprocessor, model and postprocessor)\n",
    "pipe = pipeline('object-detection', model=model_name, device_map='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess images\n",
    "preprocessed_inputs = processor([image], return_tensors='pt')\n",
    "x = preprocessed_inputs['pixel_values']\n",
    "\n",
    "# run model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**preprocessed_inputs.to(model.device))\n",
    "\n",
    "logits = outputs.logits.cpu()\n",
    "bboxes = outputs.pred_boxes.cpu()\n",
    "\n",
    "# postprocess outputs\n",
    "detections = processor.post_process_object_detection(\n",
    "    outputs,\n",
    "    threshold=0.5,\n",
    "    target_sizes=[(image.height, image.width)]\n",
    ")\n",
    "\n",
    "print(f'Images shape: {x.shape}')\n",
    "print(f'Logits shape: {logits.shape}')\n",
    "print(f'BBoxes shape: {bboxes.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize detections\n",
    "detections_iterator = zip(\n",
    "    detections[0]['scores'],\n",
    "    detections[0]['labels'],\n",
    "    detections[0]['boxes']\n",
    ")\n",
    "\n",
    "for score, label_idx, bbox in detections_iterator:\n",
    "    box = [round(coord, 2) for coord in bbox.tolist()]\n",
    "    label = model.config.id2label[label_idx.item()]\n",
    "    print(f'{label} ({score:.2f}) in {box}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show predictions\n",
    "image_array = np.array(image)\n",
    "image_tensor = torch.as_tensor(image_array)\n",
    "\n",
    "image_tensor = draw_bounding_boxes(\n",
    "    image_tensor.permute(2, 0, 1),\n",
    "    boxes=detections[0]['boxes'],\n",
    "    labels=[model.config.id2label[l] for l in detections[0]['labels'].tolist()]\n",
    ").permute(1, 2, 0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.imshow(image_tensor.numpy())\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.set_title(f'Predictions')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pipeline\n",
    "results = pipe(image)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat detections\n",
    "detections = {}\n",
    "\n",
    "detections['scores'] = torch.zeros(len(results), dtype=torch.float32)\n",
    "detections['labels'] = torch.zeros(len(results), dtype=torch.int64)\n",
    "detections['boxes'] = torch.zeros((len(results), 4), dtype=torch.float32)\n",
    "\n",
    "for idx, det in enumerate(results):\n",
    "    score = det['score']\n",
    "\n",
    "    label = det['label']\n",
    "    label_idx = model.config.label2id[label]\n",
    "\n",
    "    bbox = torch.tensor([\n",
    "        det['box']['xmin'],\n",
    "        det['box']['ymin'],\n",
    "        det['box']['xmax'],\n",
    "        det['box']['ymax']\n",
    "    ])\n",
    "\n",
    "    detections['scores'][idx] = score\n",
    "    detections['labels'][idx] = label_idx\n",
    "    detections['boxes'][idx] = bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize detections\n",
    "detections_iterator = zip(\n",
    "    detections['scores'],\n",
    "    detections['labels'],\n",
    "    detections['boxes']\n",
    ")\n",
    "\n",
    "for score, label_idx, bbox in detections_iterator:\n",
    "    box = [round(coord, 2) for coord in bbox.tolist()]\n",
    "    label = model.config.id2label[label_idx.item()]\n",
    "    print(f'{label} ({score:.2f}) in {box}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show predictions\n",
    "image_array = np.array(image)\n",
    "image_tensor = torch.as_tensor(image_array)\n",
    "\n",
    "image_tensor = draw_bounding_boxes(\n",
    "    image_tensor.permute(2, 0, 1),\n",
    "    boxes=detections['boxes'],\n",
    "    labels=[model.config.id2label[l] for l in detections['labels'].tolist()]\n",
    ").permute(1, 2, 0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.imshow(image_tensor.numpy())\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.set_title(f'Predictions')\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
