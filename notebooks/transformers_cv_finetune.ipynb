{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformers: Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from lightning.pytorch import seed_everything\n",
    "from transformers.image_utils import load_image\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "from hf_utils import (\n",
    "    CIFAR10DataModule,\n",
    "    LightningHFImageClassif,\n",
    "    LightningHFImageClassifLoRA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds\n",
    "_ = seed_everything(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "\n",
    "image = load_image(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show image\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.imshow(np.asarray(image))\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model name\n",
    "# model_name = 'microsoft/resnet-18'\n",
    "# model_name = 'google/vit-base-patch16-224'\n",
    "# model_name = 'facebook/dinov2-small'\n",
    "model_name = 'facebook/dinov2-small-imagenet1k-1-layer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create preprocessor\n",
    "processor = AutoImageProcessor.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "# initialize model\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    device_map='auto',\n",
    "    # num_labels=len(label_names),  # set number of target labels\n",
    "    # id2label={idx: label for idx, label in enumerate(label_names)},\n",
    "    # label2id={label: idx for idx, label in enumerate(label_names)},\n",
    "    # ignore_mismatched_sizes=True\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "print(f'Model device: {model.device}')\n",
    "print(f'Model dtype: {model.dtype}')\n",
    "print(f'Memory footprint: {model.get_memory_footprint() * 1e-9:.2f} GiB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess images\n",
    "preprocessed_images = processor(image, return_tensors='pt')\n",
    "x = preprocessed_images['pixel_values']\n",
    "\n",
    "# run model\n",
    "with torch.inference_mode():\n",
    "    outputs = model(**preprocessed_images.to(model.device))\n",
    "\n",
    "logits = outputs.logits.cpu()\n",
    "\n",
    "print(f'Images shape: {x.shape}')\n",
    "print(f'Logits shape: {logits.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted labels\n",
    "label_ids = logits.argmax(dim=-1)\n",
    "labels = [model.config.id2label[lidx.item()] for lidx in label_ids]\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "cifar = CIFAR10DataModule(\n",
    "    data_dir='../run/data/',\n",
    "    img_size=(224, 224),\n",
    "    img_mean=(0.485, 0.456, 0.406),\n",
    "    img_std=(0.229, 0.224, 0.225),\n",
    "    batch_size=32,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "cifar.prepare_data()  # download data if not yet done\n",
    "cifar.setup(stage='test')  # create test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get batch\n",
    "test_loader = cifar.test_dataloader()\n",
    "batch = next(iter(test_loader))\n",
    "\n",
    "x_batch = batch['pixel_values']\n",
    "y_batch = batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show example images\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(5, 5))\n",
    "for idx, ax in enumerate(axes.ravel()):\n",
    "    image = cifar.renormalize(x_batch[idx]).permute(1, 2, 0).numpy()\n",
    "    label = cifar.label_names[y_batch[idx].item()]\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(label)\n",
    "    ax.set(xticks=[], yticks=[], xlabel='', ylabel='')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = LightningHFImageClassifLoRA(\n",
    "    model_name,\n",
    "    data_dir=None,\n",
    "    num_labels=None,\n",
    "    lr=1e-04,\n",
    "    lr_schedule='constant',\n",
    "    lr_interval='epoch',\n",
    "    lr_warmup=0,\n",
    "    lr_cycles=1,\n",
    "    freeze_backbone=True,\n",
    "    lora_rank=16,\n",
    "    lora_alpha=None,\n",
    "    lora_dropout=None,\n",
    "    lora_bias='none',\n",
    "    lora_target_modules=['query', 'value'],  # specify layers to apply LoRA (linear, conv, MHA, etc.)\n",
    ")\n",
    "\n",
    "model = model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from checkpoint\n",
    "ckpt_file = f'../run/finetune/version_0/checkpoints/last.ckpt'\n",
    "# ckpt_file = f'../run/lora/version_0/checkpoints/last.ckpt'\n",
    "\n",
    "if Path(ckpt_file).is_file():\n",
    "    model = LightningHFImageClassif.load_from_checkpoint(ckpt_file, map_location=None)\n",
    "    # model = LightningHFImageClassifLoRA.load_from_checkpoint(ckpt_file, map_location=None)\n",
    "\n",
    "    model = model.eval()\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get batch of data\n",
    "test_loader = cifar.test_dataloader()\n",
    "batch = next(iter(test_loader))\n",
    "\n",
    "x_batch = batch['pixel_values']\n",
    "y_batch = batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "with torch.inference_mode():\n",
    "    y_logits = model(x_batch.to(model.device)).cpu()\n",
    "\n",
    "print(f'Images shape: {x_batch.shape}')\n",
    "print(f'Logits shape: {y_logits.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted labels\n",
    "label_ids = y_logits.argmax(dim=-1)\n",
    "labels = [model.model.config.id2label[lidx.item()] for lidx in label_ids]\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show predictions\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(5, 5))\n",
    "for idx, ax in enumerate(axes.ravel()):\n",
    "    image = cifar.renormalize(x_batch[idx]).permute(1, 2, 0).numpy()\n",
    "    label = labels[idx]\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(label)\n",
    "    ax.set(xticks=[], yticks=[], xlabel='', ylabel='')\n",
    "fig.suptitle('Predictions')\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
